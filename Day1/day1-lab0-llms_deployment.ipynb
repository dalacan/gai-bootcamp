{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d91009b3-e212-4e7b-b17e-cae759a13369",
   "metadata": {},
   "source": [
    "# Lab model deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "034bbc3c",
   "metadata": {},
   "source": [
    "Go to Sagemaker playground and subscribe to the AI21 Jurrasic-2 Mid model\n",
    "https://us-east-1.console.aws.amazon.com/sagemaker/playground?region=us-east-1#/foundation-models/playground/prodview-bzjpjkgd542au"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2eb855e0-5595-4a66-9acf-96b1c161309c",
   "metadata": {},
   "source": [
    "Run all cells and open \"day1-lab1-langchain_introductin.ipynb\" to continue the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cdd62a6-df0a-4619-8cf3-4408c46c95b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: ai21 1.1.4 does not provide the extra 'sm'\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade sagemaker --quiet\n",
    "%pip install -U \"ai21[SM]\" --quiet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8ea90d-ccc5-416c-9507-d62303f25831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json, time\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "sm_client = boto3.client('sagemaker', aws_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4c36c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Endpoints': [{'EndpointName': 'huggingface-llm-falcon-40b-instruct-bf1-2023-06-25-02-23-12-429',\n",
       "   'EndpointArn': 'arn:aws:sagemaker:us-east-1:591736166602:endpoint/huggingface-llm-falcon-40b-instruct-bf1-2023-06-25-02-23-12-429',\n",
       "   'CreationTime': datetime.datetime(2023, 6, 25, 10, 23, 13, 765000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2023, 6, 25, 10, 23, 14, 129000, tzinfo=tzlocal()),\n",
       "   'EndpointStatus': 'Creating'}],\n",
       " 'ResponseMetadata': {'RequestId': 'a9961974-43ac-4027-b5b5-e0df8cdf8390',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a9961974-43ac-4027-b5b5-e0df8cdf8390',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '324',\n",
       "   'date': 'Sun, 25 Jun 2023 02:48:22 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.list_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c67880c4-c410-49ea-8143-c02368dca7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"arn:aws:sagemaker:us-east-1:591736166602:endpoint/jumpstart-example-huggingface-llm-falco-2023-06-24-08-48-11-010\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sm_client\u001b[39m.\u001b[39;49mdelete_endpoint(EndpointName\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mjumpstart-example-huggingface-llm-falco-2023-06-24-08-48-11-010\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/botocore/client.py:964\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    962\u001b[0m     error_code \u001b[39m=\u001b[39m parsed_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    963\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 964\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    965\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    966\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"arn:aws:sagemaker:us-east-1:591736166602:endpoint/jumpstart-example-huggingface-llm-falco-2023-06-24-08-48-11-010\"."
     ]
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=\"jumpstart-example-huggingface-llm-falco-2023-06-24-08-48-11-010\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58e2b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select to reload environment variables for existing endpoint, or deploy a new endpoint\n",
    "load_endpoint=True\n",
    "\n",
    "ai21_endpoint_name = \"j2-grande-v1-0-43-6964668ff5aa38edbffbb-2023-06-25-02-50-54-631\"\n",
    "falcon_endpoint_name = \"huggingface-llm-falcon-40b-instruct-bf1-2023-06-25-02-23-12-429\"\n",
    "embedding_endpoint_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8414acdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure Falcon-40B Model\n",
    "falcon_inference_model = \"huggingface-llm-falcon-40b-instruct-bf16\"\n",
    "falcon_instance_type = \"ml.g5.12xlarge\"\n",
    "falcon_number_of_gpu = 4\n",
    "falcon_max_input_length = 1024\n",
    "falcon_max_total_tokens = 2048\n",
    "health_check_timeout = 300# Set to true to reload the environment variables for the model\n",
    "\n",
    "# Configure AI Jurassic model\n",
    "ai21_inference_model = \"j2-grande\"\n",
    "ai21_instance_type = \"ml.g5.48xlarge\"\n",
    "ai21_number_of_gpu = 4\n",
    "ai21_max_input_length = 1024\n",
    "ai21_max_total_tokens = 2048\n",
    "\n",
    "# Configure Embedding model\n",
    "embedding_model = \"huggingface-textembedding-gpt-j-6b-fp16\"\n",
    "embedding_model_instance_type = \"ml.g5.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b55d912a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#models configuration\n",
    "_MODEL_CONFIG_ = {\n",
    "    ai21_inference_model:{\n",
    "        \"provider\": \"marketplace\",\n",
    "        \"instance_type\": ai21_instance_type,\n",
    "        # \"endpoint_name\": name_from_base(f\"jumpstart-example-{ai21_inference_model.replace('/', '-')}\"),\n",
    "        \"env\": {\n",
    "            'HF_MODEL_ID': ai21_inference_model,\n",
    "            'SM_NUM_GPUS': json.dumps(ai21_number_of_gpu),\n",
    "            'MAX_INPUT_LENGTH': json.dumps(ai21_max_input_length),\n",
    "            'MAX_TOTAL_TOKENS': json.dumps(ai21_max_total_tokens),\n",
    "        },\n",
    "        \"version\":\"1.0.0\",\n",
    "    },\n",
    "    falcon_inference_model:{\n",
    "        \"provider\": \"jumpstart\",\n",
    "        \"instance_type\": falcon_instance_type,\n",
    "        # \"endpoint_name\": name_from_base(f\"jumpstart-example-{falcon_inference_model.replace('/', '-')}\"),\n",
    "        \"env\": {\n",
    "            'HF_MODEL_ID': falcon_inference_model,\n",
    "            'SM_NUM_GPUS': json.dumps(falcon_number_of_gpu),\n",
    "            'MAX_INPUT_LENGTH': json.dumps(falcon_max_input_length),\n",
    "            'MAX_TOTAL_TOKENS': json.dumps(falcon_max_total_tokens),\n",
    "        },\n",
    "        \"version\":\"1.0.0\",\n",
    "    },\n",
    "    embedding_model: {\n",
    "        \"provider\": \"jumpstart\",\n",
    "        \"instance_type\": embedding_model_instance_type,\n",
    "        \"env\": {\"TS_DEFAULT_WORKERS_PER_MODEL\": \"1\"},\n",
    "        \"version\":\"*\",\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "if load_endpoint:\n",
    "    _MODEL_CONFIG_[ai21_inference_model]['endpoint_name'] = ai21_endpoint_name\n",
    "    _MODEL_CONFIG_[falcon_inference_model]['endpoint_name'] = falcon_endpoint_name\n",
    "    _MODEL_CONFIG_[embedding_model]['endpoint_name'] = embedding_endpoint_name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1003a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage, get_execution_role\n",
    "\n",
    "def deploy_ai21(model_id: str, config: dict):\n",
    "    role = get_execution_role()\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "\n",
    "    runtime_sm_client = boto3.client(\"runtime.sagemaker\")\n",
    "    model_package_map = {\n",
    "        \"us-east-1\": \"arn:aws:sagemaker:us-east-1:865070037744:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"us-east-2\": \"arn:aws:sagemaker:us-east-2:057799348421:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"us-west-1\": \"arn:aws:sagemaker:us-west-1:382657785993:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"us-west-2\": \"arn:aws:sagemaker:us-west-2:594846645681:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"ca-central-1\": \"arn:aws:sagemaker:ca-central-1:470592106596:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"eu-central-1\": \"arn:aws:sagemaker:eu-central-1:446921602837:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"eu-west-1\": \"arn:aws:sagemaker:eu-west-1:985815980388:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"eu-west-2\": \"arn:aws:sagemaker:eu-west-2:856760150666:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"eu-west-3\": \"arn:aws:sagemaker:eu-west-3:843114510376:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"eu-north-1\": \"arn:aws:sagemaker:eu-north-1:136758871317:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"ap-southeast-1\": \"arn:aws:sagemaker:ap-southeast-1:192199979996:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"ap-southeast-2\": \"arn:aws:sagemaker:ap-southeast-2:666831318237:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"ap-northeast-2\": \"arn:aws:sagemaker:ap-northeast-2:745090734665:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"ap-northeast-1\": \"arn:aws:sagemaker:ap-northeast-1:977537786026:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"ap-south-1\": \"arn:aws:sagemaker:ap-south-1:077584701553:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\",\n",
    "        \"sa-east-1\": \"arn:aws:sagemaker:sa-east-1:270155090741:model-package/j2-grande-v1-0-43-6964668ff5aa38edbffbbb3f57e83d39\"\n",
    "    }\n",
    "    region = boto3.Session().region_name\n",
    "    if region not in model_package_map.keys():\n",
    "        raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "    model_package_arn = model_package_map[region]\n",
    "\n",
    "    # create a deployable model from the model package.\n",
    "    model = ModelPackage(\n",
    "        role=aws_role, \n",
    "        model_package_arn=model_package_arn,\n",
    "        sagemaker_session=sagemaker_session\n",
    "    )\n",
    "\n",
    "    # Deploy the model\n",
    "    predictor = model.deploy(1, \n",
    "        config['instance_type'],\n",
    "        endpoint_name=model_id, \n",
    "        model_data_download_timeout=3600,\n",
    "        container_startup_health_check_timeout=600,\n",
    "    )\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95ad751b-a879-4b04-950b-01d3c2b47b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---"
     ]
    }
   ],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "# Deploys all model endpoints in parallel\n",
    "for model_id in _MODEL_CONFIG_:\n",
    "    # if load_endpoint  and endpoint_name is set on _MODEL_CONFIG_[model_id]\n",
    "    if load_endpoint and _MODEL_CONFIG_[model_id].get(\"endpoint_name\", \"\"):\n",
    "        print(f\"{bold}Loading endpoint {_MODEL_CONFIG_[model_id]['endpoint_name']}{unbold}{newline}\")\n",
    "    else:\n",
    "        # Otherwise deploy new endpoint\n",
    "        endpoint_name = name_from_base(f\"raglc-{model_id}\")\n",
    "        endpoint_config = _MODEL_CONFIG_[model_id]\n",
    "        inference_instance_type = endpoint_config[\"instance_type\"]\n",
    "        \n",
    "        model_version = endpoint_config[\"version\"]\n",
    "        instance_type = endpoint_config[\"instance_type\"]\n",
    "        if endpoint_config[\"provider\"] == \"marketplace\":\n",
    "            deploy_ai21(model_id, endpoint_config)\n",
    "        else:\n",
    "            # Retrieve the inference container uri. This is the base HuggingFace container image for the default model above.\n",
    "            deploy_image_uri = image_uris.retrieve(\n",
    "                region=None,\n",
    "                framework=None,  # automatically inferred from model_id\n",
    "                image_scope=\"inference\",\n",
    "                model_id=model_id,\n",
    "                model_version=model_version,\n",
    "                instance_type=instance_type,\n",
    "            )\n",
    "            # Retrieve the model uri.\n",
    "            model_uri = model_uris.retrieve(\n",
    "                model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    "            )\n",
    "            model_inference = Model(\n",
    "                image_uri=deploy_image_uri,\n",
    "                model_data=model_uri,\n",
    "                role=aws_role,\n",
    "                predictor_cls=Predictor,\n",
    "                name=model_id,\n",
    "                env=endpoint_config[\"env\"],\n",
    "            )\n",
    "            model_predictor_inference = model_inference.deploy(\n",
    "                initial_instance_count=1,\n",
    "                instance_type=inference_instance_type,\n",
    "                predictor_cls=Predictor,\n",
    "                name=endpoint_config['endpoint_name'],\n",
    "            )\n",
    "\n",
    "        print(f\"{bold}Deployment of model {model_id} has been initialized.{unbold}{newline}\")\n",
    "        _MODEL_CONFIG_[model_id][\"endpoint_name\"] = endpoint_name\n",
    "\n",
    "# Await completion of endpoint deployment\n",
    "# wait=False,\n",
    "# describe_inference_endpoint_response = sm_client.describe_endpoint(EndpointName=_MODEL_CONFIG_[inference_model]['endpoint_name'])\n",
    "\n",
    "# while describe_inference_endpoint_response[\"EndpointStatus\"] == 'Creating':\n",
    "#     time.sleep(15)\n",
    "#     print('.', end='')\n",
    "#     describe_inference_endpoint_response = sm_client.describe_endpoint(EndpointName=_MODEL_CONFIG_[inference_model]['endpoint_name'])\n",
    "# print('\\nEmbedding endpoint created')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fedd940d-7338-4df4-91a2-84549be3f9a8",
   "metadata": {},
   "source": [
    "We wait for the embedding model and the inference model to be created. it usually takes 5-10 mins notably for the Flan T5 to be deployed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "076a6948-30fb-4f0b-944a-8016ee881228",
   "metadata": {},
   "source": [
    "We store few variables to be used in the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9248e11f-4d88-46af-86f8-c5e0c2f9c59f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored '_MODEL_CONFIG_' (dict)\n",
      "Stored 'inference_model' (str)\n"
     ]
    }
   ],
   "source": [
    "%store _MODEL_CONFIG_\n",
    "# %store embedding_model\n",
    "%store inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0096cf0-bc75-44e5-9b68-a1c53c901e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
