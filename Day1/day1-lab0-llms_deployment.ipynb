{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d91009b3-e212-4e7b-b17e-cae759a13369",
   "metadata": {},
   "source": [
    "# Lab model deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2eb855e0-5595-4a66-9acf-96b1c161309c",
   "metadata": {},
   "source": [
    "Run all cells and open \"day1-lab1-langchain_introductin.ipynb\" to continue the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cdd62a6-df0a-4619-8cf3-4408c46c95b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.168.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.26.153)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.24.3)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.4.4)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML==6.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.5.2)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.153 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.153)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (67.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2022.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.153->boto3<2.0,>=1.26.131->sagemaker) (1.26.16)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Do the necessary installations\n",
    "!pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa8ea90d-ccc5-416c-9507-d62303f25831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json, time\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "sm_client = boto3.client('sagemaker', aws_region)\n",
    "model_version = \"1.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c4c36c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Endpoints': [{'EndpointName': 'jumpstart-example-huggingface-llm-falco-2023-06-24-08-48-11-010',\n",
       "   'EndpointArn': 'arn:aws:sagemaker:us-east-1:591736166602:endpoint/jumpstart-example-huggingface-llm-falco-2023-06-24-08-48-11-010',\n",
       "   'CreationTime': datetime.datetime(2023, 6, 24, 16, 48, 12, 145000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2023, 6, 24, 17, 38, 54, 66000, tzinfo=tzlocal()),\n",
       "   'EndpointStatus': 'Failed'}],\n",
       " 'ResponseMetadata': {'RequestId': '1b70dd73-bf25-46ec-a166-803f24fffba5',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1b70dd73-bf25-46ec-a166-803f24fffba5',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '322',\n",
       "   'date': 'Sun, 25 Jun 2023 01:43:17 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.list_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c67880c4-c410-49ea-8143-c02368dca7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the DeleteEndpoint operation: Cannot update in-progress endpoint \"arn:aws:sagemaker:us-east-1:591736166602:endpoint/jumpstart-example-huggingface-llm-falco-2023-06-24-06-11-09-889\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEndpointName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjumpstart-example-huggingface-llm-falco-2023-06-24-06-11-09-889\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:964\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    962\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    963\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 964\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the DeleteEndpoint operation: Cannot update in-progress endpoint \"arn:aws:sagemaker:us-east-1:591736166602:endpoint/jumpstart-example-huggingface-llm-falco-2023-06-24-06-11-09-889\"."
     ]
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=\"jumpstart-example-huggingface-llm-falco-2023-06-24-06-11-09-889\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c58e2b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select to reload environment variables for existing endpoint, or deploy a new endpoint\n",
    "reload_endpoint=False\n",
    "ai21_endpoint_name = \"jumpstart-example-tiiuae-falcon-40b-ins-2023-06-23-00-23-45-305\"\n",
    "falcon_endpoint_name = \"jumpstart-example-tiiuae-falcon-40b-ins-2023-06-23-00-23-45-305\"\n",
    "embedding_endpoint_name = \"jumpstart-example-tiiuae-falcon-40b-ins-2023-06-23-00-23-45-305\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8414acdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure Falcon-40B Model\n",
    "falcon_inference_model = \"huggingface-llm-falcon-40b-instruct-bf16\"\n",
    "falcon_instance_type = \"ml.g5.12xlarge\"\n",
    "falcon_number_of_gpu = 4\n",
    "falcon_max_input_length = 1024\n",
    "falcon_max_total_tokens = 2048\n",
    "health_check_timeout = 300# Set to true to reload the environment variables for the model\n",
    "\n",
    "# Configure AI Jurassic model\n",
    "ai21_inference_model = \"ju-grande\"\n",
    "ai21_instance_type = \"ml.g5.48xlarge\"\n",
    "ai21_number_of_gpu = 4\n",
    "ai21_max_input_length = 1024\n",
    "ai21_max_total_tokens = 2048\n",
    "\n",
    "# Configure Embedding model\n",
    "embedding_model = \"huggingface-llm-embedding-bf16\"\n",
    "embedding_model_instance_type = \"ml.g5.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b55d912a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#models configuration\n",
    "_MODEL_CONFIG_ = {\n",
    "    ai21_inference_model:{\n",
    "        \"provider\": \"marketplace\",\n",
    "        \"instance_type\": ai21_instance_type,\n",
    "        \"endpoint_name\": name_from_base(f\"jumpstart-example-{ai21_inference_model.replace('/', '-')}\"),\n",
    "        \"env\": {\n",
    "            'HF_MODEL_ID': ai21_inference_model,\n",
    "            'SM_NUM_GPUS': json.dumps(ai21_number_of_gpu),\n",
    "            'MAX_INPUT_LENGTH': json.dumps(ai21_max_input_length),\n",
    "            'MAX_TOTAL_TOKENS': json.dumps(ai21_max_total_tokens),\n",
    "        },\n",
    "        \"version\":\"1.0.0\",\n",
    "    },\n",
    "    falcon_inference_model:{\n",
    "        \"provider\": \"jumpstart\",\n",
    "        \"instance_type\": falcon_instance_type,\n",
    "        \"endpoint_name\": name_from_base(f\"jumpstart-example-{falcon_inference_model.replace('/', '-')}\"),\n",
    "        \"env\": {\n",
    "            'HF_MODEL_ID': falcon_inference_model,\n",
    "            'SM_NUM_GPUS': json.dumps(falcon_number_of_gpu),\n",
    "            'MAX_INPUT_LENGTH': json.dumps(falcon_max_input_length),\n",
    "            'MAX_TOTAL_TOKENS': json.dumps(falcon_max_total_tokens),\n",
    "        },\n",
    "        \"version\":\"1.0.0\",\n",
    "    },\n",
    "    embedding_model: {\n",
    "        \"provider\": \"jumpstart\",\n",
    "        \"instance_type\": embedding_model_instance_type,\n",
    "        \"env\": {\"TS_DEFAULT_WORKERS_PER_MODEL\": \"1\"},\n",
    "        \"version\":\"*\",\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95ad751b-a879-4b04-950b-01d3c2b47b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to find model manifest for 'ju-grande' with version '1.0.0'. Visit https://sagemaker.readthedocs.io/en/stable/doc_utils/pretrainedmodels.html for updated list of models. Did you mean to use model ID 'xgboost-regression-model'?\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m instance_type \u001b[39m=\u001b[39m endpoint_config[\u001b[39m\"\u001b[39m\u001b[39minstance_type\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[39m# Retrieve the inference container uri. This is the base HuggingFace container image for the default model above.\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m deploy_image_uri \u001b[39m=\u001b[39m image_uris\u001b[39m.\u001b[39;49mretrieve(\n\u001b[1;32m     17\u001b[0m     region\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     18\u001b[0m     framework\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,  \u001b[39m# automatically inferred from model_id\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m     image_scope\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minference\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     20\u001b[0m     model_id\u001b[39m=\u001b[39;49mmodel_id,\n\u001b[1;32m     21\u001b[0m     model_version\u001b[39m=\u001b[39;49mmodel_version,\n\u001b[1;32m     22\u001b[0m     instance_type\u001b[39m=\u001b[39;49minstance_type,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[39m# Retrieve the model uri.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m model_uri \u001b[39m=\u001b[39m model_uris\u001b[39m.\u001b[39mretrieve(\n\u001b[1;32m     26\u001b[0m     model_id\u001b[39m=\u001b[39mmodel_id, model_version\u001b[39m=\u001b[39mmodel_version, model_scope\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minference\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/sagemaker/workflow/utilities.py:388\u001b[0m, in \u001b[0;36moverride_pipeline_parameter_var.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         logger\u001b[39m.\u001b[39mwarning(warning_msg_template, arg_name, func_name, \u001b[39mtype\u001b[39m(value))\n\u001b[1;32m    387\u001b[0m         kwargs[arg_name] \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mdefault_value\n\u001b[0;32m--> 388\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/sagemaker/image_uris.py:134\u001b[0m, in \u001b[0;36mretrieve\u001b[0;34m(framework, region, version, py_version, instance_type, accelerator_type, image_scope, container_version, distribution, base_framework_version, training_compiler_config, model_id, model_version, tolerate_vulnerable_model, tolerate_deprecated_model, sdk_version, inference_tool, serverless_inference_config)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    128\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mWhen retrieving the image_uri, the argument \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m should not be a pipeline variable \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) since pipeline variables are only interpreted in the pipeline execution time.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m             \u001b[39m%\u001b[39m (name, \u001b[39mtype\u001b[39m(val))\n\u001b[1;32m    131\u001b[0m         )\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m is_jumpstart_model_input(model_id, model_version):\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m artifacts\u001b[39m.\u001b[39;49m_retrieve_image_uri(\n\u001b[1;32m    135\u001b[0m         model_id,\n\u001b[1;32m    136\u001b[0m         model_version,\n\u001b[1;32m    137\u001b[0m         image_scope,\n\u001b[1;32m    138\u001b[0m         framework,\n\u001b[1;32m    139\u001b[0m         region,\n\u001b[1;32m    140\u001b[0m         version,\n\u001b[1;32m    141\u001b[0m         py_version,\n\u001b[1;32m    142\u001b[0m         instance_type,\n\u001b[1;32m    143\u001b[0m         accelerator_type,\n\u001b[1;32m    144\u001b[0m         container_version,\n\u001b[1;32m    145\u001b[0m         distribution,\n\u001b[1;32m    146\u001b[0m         base_framework_version,\n\u001b[1;32m    147\u001b[0m         training_compiler_config,\n\u001b[1;32m    148\u001b[0m         tolerate_vulnerable_model,\n\u001b[1;32m    149\u001b[0m         tolerate_deprecated_model,\n\u001b[1;32m    150\u001b[0m     )\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m training_compiler_config \u001b[39mand\u001b[39;00m (framework \u001b[39min\u001b[39;00m [HUGGING_FACE_FRAMEWORK, \u001b[39m\"\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[1;32m    153\u001b[0m     final_image_scope \u001b[39m=\u001b[39m image_scope\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/sagemaker/jumpstart/artifacts/image_uris.py:104\u001b[0m, in \u001b[0;36m_retrieve_image_uri\u001b[0;34m(model_id, model_version, image_scope, framework, region, version, py_version, instance_type, accelerator_type, container_version, distribution, base_framework_version, training_compiler_config, tolerate_vulnerable_model, tolerate_deprecated_model)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m region \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     region \u001b[39m=\u001b[39m JUMPSTART_DEFAULT_REGION_NAME\n\u001b[0;32m--> 104\u001b[0m model_specs \u001b[39m=\u001b[39m verify_model_region_and_return_specs(\n\u001b[1;32m    105\u001b[0m     model_id\u001b[39m=\u001b[39;49mmodel_id,\n\u001b[1;32m    106\u001b[0m     version\u001b[39m=\u001b[39;49mmodel_version,\n\u001b[1;32m    107\u001b[0m     scope\u001b[39m=\u001b[39;49mimage_scope,\n\u001b[1;32m    108\u001b[0m     region\u001b[39m=\u001b[39;49mregion,\n\u001b[1;32m    109\u001b[0m     tolerate_vulnerable_model\u001b[39m=\u001b[39;49mtolerate_vulnerable_model,\n\u001b[1;32m    110\u001b[0m     tolerate_deprecated_model\u001b[39m=\u001b[39;49mtolerate_deprecated_model,\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m image_scope \u001b[39m==\u001b[39m JumpStartScriptScope\u001b[39m.\u001b[39mINFERENCE:\n\u001b[1;32m    114\u001b[0m     ecr_specs \u001b[39m=\u001b[39m model_specs\u001b[39m.\u001b[39mhosting_ecr_specs\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/sagemaker/jumpstart/utils.py:392\u001b[0m, in \u001b[0;36mverify_model_region_and_return_specs\u001b[0;34m(model_id, version, scope, region, tolerate_vulnerable_model, tolerate_deprecated_model)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m scope \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m constants\u001b[39m.\u001b[39mSUPPORTED_JUMPSTART_SCOPES:\n\u001b[1;32m    387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mJumpStart models only support scopes: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(constants\u001b[39m.\u001b[39mSUPPORTED_JUMPSTART_SCOPES)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m     )\n\u001b[0;32m--> 392\u001b[0m model_specs \u001b[39m=\u001b[39m accessors\u001b[39m.\u001b[39;49mJumpStartModelsAccessor\u001b[39m.\u001b[39;49mget_model_specs(\n\u001b[1;32m    393\u001b[0m     region\u001b[39m=\u001b[39;49mregion, model_id\u001b[39m=\u001b[39;49mmodel_id, version\u001b[39m=\u001b[39;49mversion  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    394\u001b[0m )\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    397\u001b[0m     scope \u001b[39m==\u001b[39m constants\u001b[39m.\u001b[39mJumpStartScriptScope\u001b[39m.\u001b[39mTRAINING\u001b[39m.\u001b[39mvalue\n\u001b[1;32m    398\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m model_specs\u001b[39m.\u001b[39mtraining_supported\n\u001b[1;32m    399\u001b[0m ):\n\u001b[1;32m    400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mJumpStart model ID \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m and version \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mversion\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdoes not support training.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/sagemaker/jumpstart/accessors.py:129\u001b[0m, in \u001b[0;36mJumpStartModelsAccessor.get_model_specs\u001b[0;34m(region, model_id, version)\u001b[0m\n\u001b[1;32m    125\u001b[0m cache_kwargs \u001b[39m=\u001b[39m JumpStartModelsAccessor\u001b[39m.\u001b[39m_validate_and_mutate_region_cache_kwargs(\n\u001b[1;32m    126\u001b[0m     JumpStartModelsAccessor\u001b[39m.\u001b[39m_cache_kwargs, region\n\u001b[1;32m    127\u001b[0m )\n\u001b[1;32m    128\u001b[0m JumpStartModelsAccessor\u001b[39m.\u001b[39m_set_cache_and_region(region, cache_kwargs)\n\u001b[0;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m JumpStartModelsAccessor\u001b[39m.\u001b[39;49m_cache\u001b[39m.\u001b[39;49mget_specs(  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    130\u001b[0m     model_id\u001b[39m=\u001b[39;49mmodel_id, semantic_version_str\u001b[39m=\u001b[39;49mversion\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/sagemaker/jumpstart/cache.py:424\u001b[0m, in \u001b[0;36mJumpStartModelsCache.get_specs\u001b[0;34m(self, model_id, semantic_version_str)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_specs\u001b[39m(\u001b[39mself\u001b[39m, model_id: \u001b[39mstr\u001b[39m, semantic_version_str: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m JumpStartModelSpecs:\n\u001b[1;32m    416\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return specs for a given JumpStart model ID and semantic version.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \n\u001b[1;32m    418\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[39m            specs.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m     header \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_header(model_id, semantic_version_str)\n\u001b[1;32m    425\u001b[0m     spec_key \u001b[39m=\u001b[39m header\u001b[39m.\u001b[39mspec_key\n\u001b[1;32m    426\u001b[0m     specs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_s3_cache\u001b[39m.\u001b[39mget(\n\u001b[1;32m    427\u001b[0m         JumpStartCachedS3ContentKey(JumpStartS3FileType\u001b[39m.\u001b[39mSPECS, spec_key)\n\u001b[1;32m    428\u001b[0m     )\u001b[39m.\u001b[39mformatted_content\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/sagemaker/jumpstart/cache.py:355\u001b[0m, in \u001b[0;36mJumpStartModelsCache.get_header\u001b[0;34m(self, model_id, semantic_version_str)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_header\u001b[39m(\u001b[39mself\u001b[39m, model_id: \u001b[39mstr\u001b[39m, semantic_version_str: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m JumpStartModelHeader:\n\u001b[1;32m    347\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return header for a given JumpStart model ID and semantic version.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \n\u001b[1;32m    349\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39m            header.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_header_impl(model_id, semantic_version_str\u001b[39m=\u001b[39;49msemantic_version_str)\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/sagemaker/jumpstart/cache.py:400\u001b[0m, in \u001b[0;36mJumpStartModelsCache._get_header_impl\u001b[0;34m(self, model_id, semantic_version_str, attempt)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_header_impl\u001b[39m(\n\u001b[1;32m    384\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    385\u001b[0m     model_id: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    386\u001b[0m     semantic_version_str: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    387\u001b[0m     attempt: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m    388\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m JumpStartModelHeader:\n\u001b[1;32m    389\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Lower-level function to return header.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[1;32m    391\u001b[0m \u001b[39m    Allows a single retry if the cache is old.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39m        attempt (int): attempt number at retrieving a header.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m     versioned_model_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_id_semantic_version_manifest_key_cache\u001b[39m.\u001b[39;49mget(\n\u001b[1;32m    401\u001b[0m         JumpStartVersionedModelId(model_id, semantic_version_str)\n\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    403\u001b[0m     manifest \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_s3_cache\u001b[39m.\u001b[39mget(\n\u001b[1;32m    404\u001b[0m         JumpStartCachedS3ContentKey(JumpStartS3FileType\u001b[39m.\u001b[39mMANIFEST, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manifest_file_s3_key)\n\u001b[1;32m    405\u001b[0m     )\u001b[39m.\u001b[39mformatted_content\n\u001b[1;32m    406\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/sagemaker/utilities/cache.py:103\u001b[0m, in \u001b[0;36mLRUCache.get\u001b[0;34m(self, key, data_source_fallback)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lru_cache:\n\u001b[1;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_item(key, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mput(key)\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_item(key, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_item(key, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/sagemaker/utilities/cache.py:126\u001b[0m, in \u001b[0;36mLRUCache.put\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lru_cache\u001b[39m.\u001b[39mpopitem(last\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retrieval_function(  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    127\u001b[0m         key\u001b[39m=\u001b[39;49mkey, value\u001b[39m=\u001b[39;49mcurr_value\u001b[39m.\u001b[39;49melement \u001b[39mif\u001b[39;49;00m curr_value \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    128\u001b[0m     )\n\u001b[1;32m    130\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lru_cache[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mElement(\n\u001b[1;32m    131\u001b[0m     value\u001b[39m=\u001b[39mvalue, creation_time\u001b[39m=\u001b[39mdatetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow(tz\u001b[39m=\u001b[39mdatetime\u001b[39m.\u001b[39mtimezone\u001b[39m.\u001b[39mutc)\n\u001b[1;32m    132\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Coding/ml/generativeai/gai-bootcamp/Day1/.venv/lib/python3.11/site-packages/sagemaker/jumpstart/cache.py:239\u001b[0m, in \u001b[0;36mJumpStartModelsCache._get_manifest_key_from_model_id_semantic_version\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    236\u001b[0m     closest_model_id \u001b[39m=\u001b[39m get_close_matches(model_id, possible_model_ids, n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, cutoff\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    237\u001b[0m     error_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDid you mean to use model ID \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mclosest_model_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 239\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to find model manifest for 'ju-grande' with version '1.0.0'. Visit https://sagemaker.readthedocs.io/en/stable/doc_utils/pretrainedmodels.html for updated list of models. Did you mean to use model ID 'xgboost-regression-model'?\""
     ]
    }
   ],
   "source": [
    "\n",
    "if reload_endpoint:\n",
    "    _MODEL_CONFIG_[ai21_inference_model]['endpoint_name'] = ai21_endpoint_name\n",
    "    _MODEL_CONFIG_[falcon_inference_model]['endpoint_name'] = falcon_endpoint_name\n",
    "    _MODEL_CONFIG_[embedding_model]['endpoint_name'] = embedding_endpoint_name\n",
    "if not reload_endpoint:\n",
    "    newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "    # Deploys all model endpoints in parallel\n",
    "    for model_id in _MODEL_CONFIG_:\n",
    "        endpoint_config = _MODEL_CONFIG_[model_id]\n",
    "        inference_instance_type = endpoint_config[\"instance_type\"]\n",
    "        \n",
    "        model_version = endpoint_config[\"version\"]\n",
    "        instance_type = endpoint_config[\"instance_type\"]\n",
    "        if endpoint_config[\"provider\"] == \"marketplace\":\n",
    "            deploy_ai21(model_id, endpoint_config)\n",
    "        else:\n",
    "            # Retrieve the inference container uri. This is the base HuggingFace container image for the default model above.\n",
    "            deploy_image_uri = image_uris.retrieve(\n",
    "                region=None,\n",
    "                framework=None,  # automatically inferred from model_id\n",
    "                image_scope=\"inference\",\n",
    "                model_id=model_id,\n",
    "                model_version=model_version,\n",
    "                instance_type=instance_type,\n",
    "            )\n",
    "            # Retrieve the model uri.\n",
    "            model_uri = model_uris.retrieve(\n",
    "                model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    "            )\n",
    "            model_inference = Model(\n",
    "                image_uri=deploy_image_uri,\n",
    "                model_data=model_uri,\n",
    "                role=aws_role,\n",
    "                predictor_cls=Predictor,\n",
    "                name=model_id,\n",
    "                env=endpoint_config[\"env\"],\n",
    "            )\n",
    "            # model_predictor_inference = model_inference.deploy(\n",
    "            #     initial_instance_count=1,\n",
    "            #     instance_type=inference_instance_type,\n",
    "            #     predictor_cls=Predictor,\n",
    "            #     name=endpoint_config['endpoint_name'],\n",
    "            # )\n",
    "\n",
    "    print(f\"{bold}Model {model_id} has been created successfully.{unbold}{newline}\")\n",
    "\n",
    "    # Await completion of endpoint deployment\n",
    "    # wait=False,\n",
    "    # describe_inference_endpoint_response = sm_client.describe_endpoint(EndpointName=_MODEL_CONFIG_[inference_model]['endpoint_name'])\n",
    "\n",
    "    # while describe_inference_endpoint_response[\"EndpointStatus\"] == 'Creating':\n",
    "    #     time.sleep(15)\n",
    "    #     print('.', end='')\n",
    "    #     describe_inference_endpoint_response = sm_client.describe_endpoint(EndpointName=_MODEL_CONFIG_[inference_model]['endpoint_name'])\n",
    "    # print('\\nEmbedding endpoint created')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fedd940d-7338-4df4-91a2-84549be3f9a8",
   "metadata": {},
   "source": [
    "We wait for the embedding model and the inference model to be created. it usually takes 5-10 mins notably for the Flan T5 to be deployed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "076a6948-30fb-4f0b-944a-8016ee881228",
   "metadata": {},
   "source": [
    "We store few variables to be used in the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9248e11f-4d88-46af-86f8-c5e0c2f9c59f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored '_MODEL_CONFIG_' (dict)\n",
      "Stored 'inference_model' (str)\n"
     ]
    }
   ],
   "source": [
    "%store _MODEL_CONFIG_\n",
    "# %store embedding_model\n",
    "%store inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0096cf0-bc75-44e5-9b68-a1c53c901e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
