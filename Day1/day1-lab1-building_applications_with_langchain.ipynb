{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from helpers import read_env_file \n",
    "\n",
    "vars = read_env_file('../.env')\n",
    "llm = OpenAI(temperature=0, openai_api_key=vars['OPENAI_API_KEY'])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building applications with Models\n",
    "Chat models are a powerful variant of LLMs for interactive workflows as they are trained to expect structured input. This enables them to be highly attentive to details of the information provided and takes off burden from the developer to phrase the distinction between the inputs in their prompt\n",
    "\n",
    "\n",
    "## Scope of the notebook\n",
    "Building on top of the core primitives in LangChain in [01_setting_up.ipynb](01_setting_up.ipynb) we will dive into best practices to build application with Models in LangChain.\n",
    "\n",
    "## What we will learn\n",
    "1. How to augment your models with memory to retain short term information throughout a sessino\n",
    "2. How to load information into your application and make it available as context\n",
    "3. How to build complex chains with general routing models and specific task model chains to accomplish integrations with a variety of sub systems such as Databases, Knowledge Graphs, Search Indices and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n"
     ]
    }
   ],
   "source": [
    "from helpers import get_aws_llm\n",
    "\n",
    "llm = get_aws_llm(\n",
    "    endpoint_name=\"jumpstart-dft-falcon-7b-instruct-bf16\",\n",
    "    credentials_profile_name='default',\n",
    "    region_name=\"us-east-1\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 1e-10\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting your model with memory\n",
    "Now"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with external data\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building complex chains "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
